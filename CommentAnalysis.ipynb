{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1><u> COMMENT ANALYSIS </u></h1></center>\n",
    "<center><h3><u> USING CLASSIFICATION  </u></h3></center>\n",
    "<center><h1><u>  </u></h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# LEMMATIZATION \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import Word  #datapreparation\n",
    "# STOP WORDS \n",
    "from nltk.corpus import stopwords #datapreparation\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#Naive Bayes with count vectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "#SVM \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARSING DATA\n",
    "train = pd.read_csv('data/train.csv',low_memory=False)\n",
    "labels = pd.read_csv('data/impermium_verification_labels.csv',low_memory=False)\n",
    "sets = pd.read_csv('data/impermium_verification_set.csv',low_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>1</td>\n",
       "      <td>20120502172717Z</td>\n",
       "      <td>\"you are both morons and that is never happening\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528164814Z</td>\n",
       "      <td>\"Many toolbars include spell check, like Yahoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>0</td>\n",
       "      <td>20120620142813Z</td>\n",
       "      <td>\"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528205648Z</td>\n",
       "      <td>\"How about Felix? He is sure turning into one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>0</td>\n",
       "      <td>20120515200734Z</td>\n",
       "      <td>\"You're all upset, defending this hipster band...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3947 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult             Date  \\\n",
       "0          1  20120618192155Z   \n",
       "1          0  20120528192215Z   \n",
       "2          0              NaN   \n",
       "3          0              NaN   \n",
       "4          0  20120619094753Z   \n",
       "...      ...              ...   \n",
       "3942       1  20120502172717Z   \n",
       "3943       0  20120528164814Z   \n",
       "3944       0  20120620142813Z   \n",
       "3945       0  20120528205648Z   \n",
       "3946       0  20120515200734Z   \n",
       "\n",
       "                                                Comment  \n",
       "0                                  \"You fuck your dad.\"  \n",
       "1     \"i really don't understand your point.\\xa0 It ...  \n",
       "2     \"A\\\\xc2\\\\xa0majority of Canadians can and has ...  \n",
       "3     \"listen if you dont wanna get married to a man...  \n",
       "4     \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...  \n",
       "...                                                 ...  \n",
       "3942  \"you are both morons and that is never happening\"  \n",
       "3943  \"Many toolbars include spell check, like Yahoo...  \n",
       "3944  \"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...  \n",
       "3945  \"How about Felix? He is sure turning into one ...  \n",
       "3946  \"You're all upset, defending this hipster band...  \n",
       "\n",
       "[3947 rows x 3 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20120603163526Z</td>\n",
       "      <td>\"like this if you are a tribe fan\"</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20120531215447Z</td>\n",
       "      <td>\"you're idiot.......................\"</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20120823164228Z</td>\n",
       "      <td>\"I am a woman Babs, and the only \"war on women...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20120826010752Z</td>\n",
       "      <td>\"WOW &amp; YOU BENEFITTED SO MANY WINS THIS YEAR F...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20120602223825Z</td>\n",
       "      <td>\"haha green me red you now loser whos winning ...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>2231</td>\n",
       "      <td>0</td>\n",
       "      <td>20120528100303Z</td>\n",
       "      <td>\"FUCKIN LAME COME ON WTF STOP FUCKING OVER MY ...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>2232</td>\n",
       "      <td>1</td>\n",
       "      <td>20120531185813Z</td>\n",
       "      <td>\"YOU SHUT YOUR IGNORANT PIE HOLE YOU LITTLE IN...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>2233</td>\n",
       "      <td>0</td>\n",
       "      <td>20120529130822Z</td>\n",
       "      <td>\"sweetie pie is looking very much like her cou...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>2234</td>\n",
       "      <td>1</td>\n",
       "      <td>20120531045826Z</td>\n",
       "      <td>\"ball4real where are you with your miami g-ayn...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>2235</td>\n",
       "      <td>0</td>\n",
       "      <td>20120531184524Z</td>\n",
       "      <td>\"Man....if you are a 3 point shooter, you must...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2235 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Insult             Date  \\\n",
       "0        1       0  20120603163526Z   \n",
       "1        2       1  20120531215447Z   \n",
       "2        3       1  20120823164228Z   \n",
       "3        4       1  20120826010752Z   \n",
       "4        5       1  20120602223825Z   \n",
       "...    ...     ...              ...   \n",
       "2230  2231       0  20120528100303Z   \n",
       "2231  2232       1  20120531185813Z   \n",
       "2232  2233       0  20120529130822Z   \n",
       "2233  2234       1  20120531045826Z   \n",
       "2234  2235       0  20120531184524Z   \n",
       "\n",
       "                                                Comment        Usage  \n",
       "0                    \"like this if you are a tribe fan\"  PrivateTest  \n",
       "1                 \"you're idiot.......................\"  PrivateTest  \n",
       "2     \"I am a woman Babs, and the only \"war on women...  PrivateTest  \n",
       "3     \"WOW & YOU BENEFITTED SO MANY WINS THIS YEAR F...  PrivateTest  \n",
       "4     \"haha green me red you now loser whos winning ...  PrivateTest  \n",
       "...                                                 ...          ...  \n",
       "2230  \"FUCKIN LAME COME ON WTF STOP FUCKING OVER MY ...  PrivateTest  \n",
       "2231  \"YOU SHUT YOUR IGNORANT PIE HOLE YOU LITTLE IN...  PrivateTest  \n",
       "2232  \"sweetie pie is looking very much like her cou...  PrivateTest  \n",
       "2233  \"ball4real where are you with your miami g-ayn...  PrivateTest  \n",
       "2234  \"Man....if you are a 3 point shooter, you must...  PrivateTest  \n",
       "\n",
       "[2235 rows x 5 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace = True) # remove null rows \n",
    "train.reset_index(inplace = True)\n",
    "labels.dropna(inplace = True)\n",
    "labels.reset_index(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESSING DOCUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOWERCASE LETTERS \n",
    "train['Comment'] = train['Comment'].apply(lambda x: x.lower())\n",
    "# REMOVE ENDLINES\n",
    "train['Comment'] = train['Comment'].str.replace('\\n','')\n",
    "# REMOVE LINKS\n",
    "train['Comment'] = train['Comment'].str.replace('https?:\\/\\/.*[\\r\\n]*',' ')\n",
    "train['Comment'] = train['Comment'].str.replace('http?:\\/\\/.*[\\r\\n]*',' ')\n",
    "\n",
    "# REMOVE SPECIFIED NON ASCII\n",
    "train['Comment'] = train['Comment'].str.replace('\\u0111' ,' ')\n",
    "\n",
    "# REMOVE ALL NON ASCII\n",
    "train['Comment'] = train['Comment'].str.encode(\"ascii\", \"ignore\")\n",
    "train['Comment'] = train['Comment'].str.decode(\"unicode_escape\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICATION WITH NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5261744966442953\n"
     ]
    }
   ],
   "source": [
    "x_train = train['Comment']\n",
    "x_test = labels['Comment']\n",
    "y_train = train['Insult']\n",
    "y_test = labels['Insult']\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "x_train_cv = count_vectorizer.fit_transform(x_train)\n",
    "x_test_cv =  count_vectorizer.transform(x_test)\n",
    "\n",
    "model = GaussianNB()\n",
    "\n",
    "temp_cv = x_train_cv.toarray()\n",
    "\n",
    "model.fit(temp_cv ,y_train)\n",
    "predictions = model.predict(x_test_cv.toarray())\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES IMPROVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.654586129753915\n"
     ]
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "train['Comment'] = train['Comment'].apply(lambda x:\" \".join([word for word in x.split() if word not in (stop)])) \n",
    "                                                                                    # removing the stopwords\n",
    "                                                                                    \n",
    "train['Comment'] = train['Comment'].mask(train['Comment'].map(len) == 1, ' ') # Here we are removing the words with lengh =1 \n",
    "\n",
    "\n",
    "train['Comment'] = train['Comment'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()])) #Lemmatizing\n",
    "\n",
    "x_train = train['Comment']\n",
    "x_test = labels['Comment']\n",
    "y_train = train['Insult']\n",
    "y_test = labels['Insult']\n",
    "\n",
    "count_vectorizer = CountVectorizer(max_df=1.0, min_df=1, ngram_range = (1,2) , max_features=1000)\n",
    "\n",
    "x_train_cv = count_vectorizer.fit_transform(x_train)\n",
    "x_test_cv =  count_vectorizer.transform(x_test)\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()  \n",
    "\n",
    "temp_cv = x_train_cv.toarray()\n",
    "\n",
    "\n",
    "#vectorizer\n",
    "model.fit(temp_cv ,y_train)\n",
    "predictions = model.predict(x_test_cv.toarray())\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A FUNCTION TO COUNT POS TAGS\n",
    "def count_pos(sentence,pos):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "\n",
    "    t = 0\n",
    "    \n",
    "    for _,tag in tags:\n",
    "        if (tag ==pos) :\n",
    "            t += 1\n",
    "    if len(tags)==0 :\n",
    "        return 0\n",
    "    return ( (t/len(tags)) *100 )      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADDING TO THE TRAIN DATA SET 4 EXTRA COLUMNS FOR EACH PART OF SPEECH WITH ITS COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['NN'] = train['Comment'].apply(lambda x: count_pos(x,'NN'))\n",
    "train['JJ'] = train['Comment'].apply(lambda x: count_pos(x,'JJ'))\n",
    "train['VB'] = train['Comment'].apply(lambda x: count_pos(x,'VB'))\n",
    "train['RB'] = train['Comment'].apply(lambda x: count_pos(x,'RB'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREVIEW OF THE FINAL NEW DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>NN</th>\n",
       "      <th>JJ</th>\n",
       "      <th>VB</th>\n",
       "      <th>RB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20120618192155Z</td>\n",
       "      <td>\"you fuck dad.\"</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20120528192215Z</td>\n",
       "      <td>\"i really understand point. seems mixing apple...</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20120619094753Z</td>\n",
       "      <td>\"các bạn xuống đường biểu tình 2011 có ôn hoà ...</td>\n",
       "      <td>57.894737</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>1.052632</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>20120620171226Z</td>\n",
       "      <td>\"@sdl ok, would hope they'd sign one-year cont...</td>\n",
       "      <td>22.580645</td>\n",
       "      <td>19.354839</td>\n",
       "      <td>12.903226</td>\n",
       "      <td>3.225806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>20120503012628Z</td>\n",
       "      <td>\"yeah now?\"</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>3942</td>\n",
       "      <td>1</td>\n",
       "      <td>20120502172717Z</td>\n",
       "      <td>\"you moron never happening\"</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225</th>\n",
       "      <td>3943</td>\n",
       "      <td>0</td>\n",
       "      <td>20120528164814Z</td>\n",
       "      <td>\"many toolbars include spell check, like yahoo...</td>\n",
       "      <td>21.739130</td>\n",
       "      <td>8.695652</td>\n",
       "      <td>13.043478</td>\n",
       "      <td>4.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3226</th>\n",
       "      <td>3944</td>\n",
       "      <td>0</td>\n",
       "      <td>20120620142813Z</td>\n",
       "      <td>\"@lambeauorwrigley @k.moss sioux falls, s.d. t...</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>3945</td>\n",
       "      <td>0</td>\n",
       "      <td>20120528205648Z</td>\n",
       "      <td>\"how felix? sure turning one hell starting pit...</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>3946</td>\n",
       "      <td>0</td>\n",
       "      <td>20120515200734Z</td>\n",
       "      <td>\"you're upset, defending hipster band...and we...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>6.818182</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>4.545455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3229 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Insult             Date  \\\n",
       "0         0       1  20120618192155Z   \n",
       "1         1       0  20120528192215Z   \n",
       "2         4       0  20120619094753Z   \n",
       "3         5       0  20120620171226Z   \n",
       "4         6       0  20120503012628Z   \n",
       "...     ...     ...              ...   \n",
       "3224   3942       1  20120502172717Z   \n",
       "3225   3943       0  20120528164814Z   \n",
       "3226   3944       0  20120620142813Z   \n",
       "3227   3945       0  20120528205648Z   \n",
       "3228   3946       0  20120515200734Z   \n",
       "\n",
       "                                                Comment         NN         JJ  \\\n",
       "0                                       \"you fuck dad.\"   0.000000  16.666667   \n",
       "1     \"i really understand point. seems mixing apple...  16.666667   8.333333   \n",
       "2     \"các bạn xuống đường biểu tình 2011 có ôn hoà ...  57.894737   5.263158   \n",
       "3     \"@sdl ok, would hope they'd sign one-year cont...  22.580645  19.354839   \n",
       "4                                           \"yeah now?\"  20.000000   0.000000   \n",
       "...                                                 ...        ...        ...   \n",
       "3224                        \"you moron never happening\"   0.000000   0.000000   \n",
       "3225  \"many toolbars include spell check, like yahoo...  21.739130   8.695652   \n",
       "3226  \"@lambeauorwrigley @k.moss sioux falls, s.d. t...  40.000000   4.000000   \n",
       "3227  \"how felix? sure turning one hell starting pit...  32.000000   4.000000   \n",
       "3228  \"you're upset, defending hipster band...and we...  25.000000   6.818182   \n",
       "\n",
       "             VB         RB  \n",
       "0      0.000000   0.000000  \n",
       "1      8.333333   8.333333  \n",
       "2      1.052632   0.000000  \n",
       "3     12.903226   3.225806  \n",
       "4      0.000000  20.000000  \n",
       "...         ...        ...  \n",
       "3224   0.000000  16.666667  \n",
       "3225  13.043478   4.347826  \n",
       "3226   0.000000   0.000000  \n",
       "3227   8.000000   0.000000  \n",
       "3228   9.090909   4.545455  \n",
       "\n",
       "[3229 rows x 8 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF - IDF FOR PART OF SPEECH \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "\n",
    "x_train_tf = tfidf.fit_transform(x_train)\n",
    "x_test_tf = tfidf.transform(x_test)\n",
    " \n",
    "x_train_tf = pd.DataFrame(x_train_tf.toarray())\n",
    "x_test_tf = pd.DataFrame(x_test_tf.toarray())\n",
    "\n",
    "x_train_fin = pd.concat([train['RB'], train['VB'],train['JJ'],train['NN'], x_train_tf], axis=1)\n",
    "x_test_fin =pd.concat([train['RB'], train['VB'],train['JJ'],train['NN'], x_test_tf], axis=1)\n",
    "\n",
    "x_train_fin.dropna(inplace = True) # remove null rows \n",
    "x_train_fin.reset_index(inplace = True)\n",
    "\n",
    "x_test_fin.dropna(inplace = True) # remove null rows \n",
    "x_test_fin.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM WITH TF IDF FOR PART OF SPEECH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5181208053691275\n",
      "F1 0.701455685248928 [0.6996904  0.6996904  0.6996904  0.6996904  0.70278638 0.70278638\n",
      " 0.70278638 0.70278638 0.70278638 0.70186335]\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.svm.SVC()\n",
    "\n",
    "#vectorizer\n",
    "model.fit(x_train_fin,y_train)\n",
    "predictions = model.predict(x_test_fin)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "f1s = cross_val_score(model,x_train_fin, y_train, cv=10, scoring='f1_micro')\n",
    "print ('F1', np.mean(f1s), f1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST WITH TF IDF FOR PART OF SPEECH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5181208053691275\n",
      "F1 0.701455685248928 [0.6996904  0.6996904  0.6996904  0.6996904  0.70278638 0.70278638\n",
      " 0.70278638 0.70278638 0.70278638 0.70186335]\n"
     ]
    }
   ],
   "source": [
    "#Random Forest with tfidf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "\n",
    "#vectorizer\n",
    "model.fit(x_train_fin ,y_train)\n",
    "predictions = model.predict(x_test_fin)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "f1s = cross_val_score(model,x_train_fin, y_train, cv=10, scoring='f1_micro')\n",
    "print ('F1', np.mean(f1s), f1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPROVING F1 SCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC \n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# tuned_parameters = {'kernel':['linear','rbf'],'gamma':[1e-3,1e-4],'C':[1,10,100,1000]}\n",
    "\n",
    "# model = GridSearchCV(sklearn.svm.SVC(),tuned_parameters)\n",
    "\n",
    "# model.fit(x_train_fin,y_train)\n",
    "# print(\"Better SVM is : \")\n",
    "# print(model.score(x_test_fin,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice: I left the improving block to run for about 4 hours and nothing happened , was still running but i was out of time and I had to send the project. Thats the reason that I marked the whole block as a comment. Keep an eye to the code !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources - References \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the ideas - code that i used are based on Project 1 and Project 2 . <br>\n",
    "Project 1 : https://github.com/bakalianosm/AirBnB-Data-Exploration <br>\n",
    "Project 2 : https://github.com/bakalianosm/Data-Mining-Clustering-Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming - Lematization :https://www.datacamp.com/community/tutorials/stemming-lemmatization-python?utm_source=adwords_ppc&utm_campaignid=9942305733&utm_adgroupid=100189364546&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=&utm_creative=255798340456&utm_targetid=aud-517318241987:dsa-929501846124&utm_loc_interest_ms=&utm_loc_physical_ms=9067678&gclid=CjwKCAjw8pH3BRAXEiwA1pvMseromhRhaTZCIswco13hTLG2yBxTds6MnnD3xVVsszDdGz7URPWZyxoC3igQAvD_BwE\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords Removal: https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laplace Smoothing: https://towardsdatascience.com/introduction-to-na%C3%AFve-bayes-classifier-fa59e3e24aaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of Speech Tagging: https://www.nltk.org/book/ch05.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe Concatenation: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links Removal: https://stackoverflow.com/questions/51994254/removing-url-from-a-column-in-pandas-dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive - Bayes Classification https://scikit-learn.org/stable/modules/naive_bayes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
